{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm \n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    filename='train.csv'\n",
    "elif MODE=='test':\n",
    "    filename='Xtest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename, \n",
    "                   header=0, \n",
    "                   sep=',',\n",
    "                   encoding = \"windows-1251\", \n",
    "                   error_bad_lines=False)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(data['Password'])\n",
    "X=X['Password'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    y=data['Times']\n",
    "    y=y.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_pred, y_test) : \n",
    "    assert len(y_test) == len(y_pred)\n",
    "    return np.sqrt(np.mean((np.log(1+y_pred) - np.log(1+y_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSymbols(words):\n",
    "    symbols=set()\n",
    "    for q in range(words.shape[0]):\n",
    "        for w in range(len(words[q])):\n",
    "            symbols.add(words[q][w])\n",
    "    return np.array(list(symbols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word):\n",
    "    count=0\n",
    "    for i_s in range(len(symbs)):\n",
    "        if(symbs[i_s] in word):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllSuffixes(words, times):\n",
    "    suffixes={}\n",
    "    suffixescounts={}\n",
    "    for word in words:\n",
    "        for q in range(len(word)):\n",
    "            tempword=str(word[q])\n",
    "            for w in range(q+1, len(word)):\n",
    "                tempword+=word[w]\n",
    "                if suffixes.get(tempword)==None:\n",
    "                    suffixes[tempword]=times[q]\n",
    "                    suffixescounts[tempword]=1\n",
    "                else:\n",
    "                    suffixes[tempword]+=times[q]\n",
    "                    suffixescounts[tempword]+=1\n",
    "\n",
    "            \n",
    "    return [suffixes, suffixescounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Thresh_complete(times_thresh ,df):\n",
    "    primery_th=df[(df.Times >times_thresh)]\n",
    "    primery_th_pss= list(primery_th['Password'].apply(str))\n",
    "    primery_th_times= list(primery_th['Times'].apply(int))\n",
    "    \n",
    "    suffixes= getAllSuffixes(primery_th_pss, primery_th_times)\n",
    "    return suffixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    alphabet= [\"a\", \"b\", \"c\", \"d\", 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z' ]\n",
    "    alphabetUp= ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z' ]\n",
    "\n",
    "    vowelUp= ['A', 'E', 'I', 'O', 'U']\n",
    "    vowel= ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "    digits=['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "    consonant=[ \"b\", \"c\", \"d\", 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z' ]\n",
    "    consonantUp=['B',\"C\", 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z' ]\n",
    "\n",
    "    allsym = getSymbols(X.values.reshape(-1))\n",
    "    othersym= list(set(allsym) - set(alphabet) - set(alphabetUp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    timesthresh=100\n",
    "    freq=45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    thresh = get_Thresh_complete(timesthresh,data)\n",
    "    val=list(thresh[0].values())\n",
    "    cts=list(thresh[1].values())\n",
    "    keys=list(thresh[0].keys())\n",
    "\n",
    "    for q in range(len(val)):\n",
    "        val[q]=val[q]/cts[q]\n",
    "    tempdf= pd.DataFrame()\n",
    "    tempdf['val']= val\n",
    "    tempdf['cts']= cts\n",
    "    tempdf['keys']=keys\n",
    "    \n",
    "    tempdf= tempdf[(tempdf['cts']>= freq)]\n",
    "    val=tempdf['val'].values\n",
    "    cts=tempdf['cts'].values\n",
    "    \n",
    "    keys=tempdf['keys'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firstvowel']= X.apply(lambda x: x[0] in vowel )\n",
    "df['firstvowelUp']= X.apply(lambda x: x[0] in vowelUp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firstcons']= X.apply(lambda x: x[0] in consonant )\n",
    "df['firstconsUp']= X.apply(lambda x: x[0] in consonantUp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firstdigit']= X.apply(lambda x: x[0] in digits )\n",
    "df['firstother']= X.apply(lambda x: x[0] in othersym )\n",
    "\n",
    "df['lastdigit']= X.apply(lambda x: x[-1] in digits )\n",
    "df['lastother']= X.apply(lambda x: x[-1] in othersym )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fupper']=X.apply(lambda x: x[0].isupper())\n",
    "df['lupper']=X.apply(lambda x: x[-1].isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isdigit']=X.apply(lambda x: x.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['islower']=X.apply(lambda x: x.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fupper']=X.apply(lambda x: x.isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for q in range(len(allsym)):\n",
    "    df[str(q)+'symbol']=X.apply(lambda x : allsym[q] in x)\n",
    "    if q%10==0:\n",
    "        print(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary=list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cnt']=X.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs=vowel\n",
    "df['conscnt']=X.apply(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs=consonant\n",
    "df['vowcnt']=X.apply(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs=consonantUp\n",
    "df['consUpcnt']=X.apply(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs=vowelUp\n",
    "df['vowUpcnt']=X.apply(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs=digits\n",
    "df['digitscnt']=X.apply(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs=othersym\n",
    "df['othersymcnt']=X.apply(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric= list(set(df.columns) - set(binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEYS FEATURES GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "CPU times: user 35.1 s, sys: 79.9 ms, total: 35.1 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for q in range(len(keys)):\n",
    "    df[str(q) + '_key']= X.apply(lambda x: keys[q] in x )\n",
    "    if q%50==0:\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INIT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "    RandomForestRegressor(max_depth=2,verbose=1, n_estimators=100, n_jobs=-1),\n",
    "    linear_model.SGDRegressor(max_iter=2000, tol=0.1, verbose=1),\n",
    "    GradientBoostingRegressor(verbose=1),\n",
    "    CatBoostRegressor(iterations=500,learning_rate=0.1, depth=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHOOSE MODEL NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index= 1\n",
    "model=models[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE='validation_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=_test_size, random_state=42)\n",
    "elif MODE=='validation_full':\n",
    "    X_train=df\n",
    "    y_train=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation' or 'validation_full':\n",
    "    model.fit(X_train, np.log(y_train +1))\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 244, Bias: 0.743287, T: 100000, Avg. loss: 0.080971\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 247, Bias: 0.782036, T: 100000, Avg. loss: 0.078251\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 248, Bias: 0.804723, T: 100000, Avg. loss: 0.080575\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 250, Bias: 0.815090, T: 100000, Avg. loss: 0.080062\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 250, Bias: 0.827435, T: 100000, Avg. loss: 0.080509\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 250, Bias: 0.835380, T: 100000, Avg. loss: 0.080367\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 251, Bias: 0.834223, T: 100000, Avg. loss: 0.080908\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 251, Bias: 0.834224, T: 100000, Avg. loss: 0.081252\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 251, Bias: 0.830369, T: 100000, Avg. loss: 0.080178\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 251, Bias: 0.828817, T: 100000, Avg. loss: 0.077572\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.827566, T: 100000, Avg. loss: 0.077820\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 252, Bias: 0.831150, T: 100000, Avg. loss: 0.080522\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.832804, T: 100000, Avg. loss: 0.078315\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.834478, T: 100000, Avg. loss: 0.074654\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.839318, T: 100000, Avg. loss: 0.078047\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 252, Bias: 0.837717, T: 100000, Avg. loss: 0.079131\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.838414, T: 100000, Avg. loss: 0.077795\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.835897, T: 100000, Avg. loss: 0.079578\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 252, Bias: 0.838748, T: 100000, Avg. loss: 0.077310\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 253, Bias: 0.839870, T: 100000, Avg. loss: 0.078216\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 254, Bias: 0.845991, T: 100000, Avg. loss: 0.080344\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 254, Bias: 0.844921, T: 100000, Avg. loss: 0.079423\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 254, Bias: 0.842940, T: 100000, Avg. loss: 0.079017\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 254, Bias: 0.833483, T: 100000, Avg. loss: 0.075291\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.848887, T: 100000, Avg. loss: 0.079610\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.841742, T: 100000, Avg. loss: 0.078667\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.844500, T: 100000, Avg. loss: 0.079063\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 255, Bias: 0.849336, T: 100000, Avg. loss: 0.080355\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.845125, T: 100000, Avg. loss: 0.079696\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.841477, T: 100000, Avg. loss: 0.079869\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.842067, T: 100000, Avg. loss: 0.077371\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 255, Bias: 0.852286, T: 100000, Avg. loss: 0.080637\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 256, Bias: 0.846184, T: 100000, Avg. loss: 0.079860\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 256, Bias: 0.849391, T: 100000, Avg. loss: 0.078686\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 256, Bias: 0.842180, T: 100000, Avg. loss: 0.078140\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 256, Bias: 0.845360, T: 100000, Avg. loss: 0.078801\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 256, Bias: 0.846510, T: 100000, Avg. loss: 0.077909\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 256, Bias: 0.858850, T: 100000, Avg. loss: 0.078231\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 256, Bias: 0.854022, T: 100000, Avg. loss: 0.081783\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 256, Bias: 0.843219, T: 100000, Avg. loss: 0.076208\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 0.53, NNZs: 256, Bias: 0.849720, T: 100000, Avg. loss: 0.077544\n",
      "Total training time: 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "for q in range(0, len(X_train)-100000,100000):\n",
    "    model.partial_fit(X_train[q: q+100000], np.log(y_train[q: q+100000] +1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='validation':\n",
    "    preds= np.exp(model.predict(X_test))-1\n",
    "    rmsle(y_test.values, preds)\n",
    "elif MODE== 'test':\n",
    "    preds= np.exp(model.predict(df))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = {'Id' : range(df.shape[0]), 'Times': preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE=='test':\n",
    "\n",
    "    dfconst.to_csv('Answers_140_feats.csv' ,encoding = \"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSNTANT SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minfunc = minimize(rmsle,x0=1,method='BFGS', tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Passes=np.array([minfunc.x[0]]*data['Id'].shape[0])\n",
    "dftemp = {'Id' : range(Passes.shape[0]), 'Times': Passes}\n",
    "dfconst=pd.DataFrame(dftemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconst.to_csv('constAns.csv' ,encoding = \"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconst.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
