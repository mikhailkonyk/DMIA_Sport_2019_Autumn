{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Kaggle API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle.api_client import ApiClient\n",
    "api = KaggleApi(ApiClient())\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition = 'dmia-sport-2019-fall-intro'\n",
    "train_file = os.path.join('..','input',competition,'train.csv')\n",
    "test_file = os.path.join('..','input',competition,'Xtest.csv')\n",
    "split_seed = 7\n",
    "split_part =0.3\n",
    "model_seed = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gleb\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_file, dtype={'Password': str, 'Times': np.int32})\n",
    "x_test = pd.read_csv(test_file, index_col=0, dtype={'Password': str, 'Id': np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(train['Password'])\n",
    "y = np.log(train['Times']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyboard Ditance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_COST = 3.0\n",
    "NONE_COST = 10\n",
    "\n",
    "qwertyKeyboardArray = [\n",
    "    ['`','1','2','3','4','5','6','7','8','9','0','-','='],\n",
    "    ['q','w','e','r','t','y','u','i','o','p','[',']','\\\\'],\n",
    "    ['a','s','d','f','g','h','j','k','l',';','\\''],\n",
    "    ['z','x','c','v','b','n','m',',','.','/'],\n",
    "    ['', '', ' ', ' ', ' ', ' ', ' ', '', '']\n",
    "    ]\n",
    "\n",
    "qwertyShiftedKeyboardArray = [\n",
    "    ['~', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '+'],\n",
    "    ['Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', '{', '}', '|'],\n",
    "    ['A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', ':', '\"'],\n",
    "    ['Z', 'X', 'C', 'V', 'B', 'N', 'M', '<', '>', '?'],\n",
    "    ['', '', ' ', ' ', ' ', ' ', ' ', '', '']\n",
    "    ]\n",
    "\n",
    "keyboardArray = qwertyKeyboardArray\n",
    "shiftedKeyboardArray = qwertyShiftedKeyboardArray\n",
    "\n",
    "def arrayForChar(c):\n",
    "    if (True in [c in r for r in keyboardArray]):\n",
    "        return keyboardArray\n",
    "    elif (True in [c in r for r in shiftedKeyboardArray]):\n",
    "        return shiftedKeyboardArray\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def getCharacterCoord(c, array=qwertyKeyboardArray):\n",
    "    row = -1\n",
    "    column = -1\n",
    "    for r in array:\n",
    "        if c in r:\n",
    "            row = array.index(r)\n",
    "            column = r.index(c)\n",
    "            return (row, column)\n",
    "    return None\n",
    "    \n",
    "def euclideanKeyboardDistance(c1, c2):\n",
    "    array1, array2 = arrayForChar(c1), arrayForChar(c2)\n",
    "    if array1 is None or array2 is None:\n",
    "        return NONE_COST\n",
    "    coord1 = getCharacterCoord(c1, arrayForChar(c1))\n",
    "    coord2 = getCharacterCoord(c2, arrayForChar(c2))\n",
    "    return ((coord1[0] - coord2[0])**2 + (coord1[1] - coord2[1])**2)**(0.5) + (0 if array1 == array2 else SHIFT_COST)\n",
    "\n",
    "def wordTotalDistance(word):\n",
    "    sum = 0\n",
    "    for i in range(len(word)-1):\n",
    "        sum += euclideanKeyboardDistance(word[i], word[i+1])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictogram(dict):\n",
    "    def __init__(self, iterable=None):\n",
    "        # Инициализируем наше распределение как новый объект класса, \n",
    "        # добавляем имеющиеся элементы\n",
    "        super(Dictogram, self).__init__()\n",
    "        self.types = 0  # число уникальных ключей в распределении\n",
    "        self.tokens = 0  # общее количество всех слов в распределении\n",
    "        if iterable:\n",
    "            self.update(iterable)\n",
    "\n",
    "    def update(self, iterable):\n",
    "        # Обновляем распределение элементами из имеющегося \n",
    "        # итерируемого набора данных\n",
    "        for item in iterable:\n",
    "            if item in self:\n",
    "                self[item] += 1\n",
    "                self.tokens += 1\n",
    "            else:\n",
    "                self[item] = 2 # Laplass smooth\n",
    "                self.types += 1\n",
    "                self.tokens += 2 # Laplass smooth\n",
    "\n",
    "class MarkovChain(dict):\n",
    "    def __init__(self, power=1):\n",
    "        super(MarkovChain, self).__init__()\n",
    "        self.power = power - 1\n",
    "    \n",
    "    def fit(self, words):\n",
    "        for word in words:\n",
    "            w = ' ' * self.power + str(word).lower() +' ' * self.power\n",
    "            for sh in range(self.power+2):\n",
    "                grams = [w[i:i+self.power+1] for i in range(sh,len(w)-self.power+2-sh)]\n",
    "                for c1, c2 in zip(grams, grams[1+self.power:]):\n",
    "                    if c1 in self:\n",
    "                        # Просто присоединяем к уже существующему распределению\n",
    "                        self[c1].update([c2])\n",
    "                    else:\n",
    "                        self[c1] = Dictogram([c2])\n",
    "        \n",
    "    def get_pair_proba(self, ch1, ch2):\n",
    "        if ch1 in self:\n",
    "            if ch2 in self[ch1]:\n",
    "                return self[ch1][ch2]/self[ch1].tokens\n",
    "            else:\n",
    "                return 1/(self[ch1].tokens + 1)\n",
    "        else:\n",
    "            return 1.0\n",
    "        \n",
    "    def proba(self, word):\n",
    "        w = ' ' * self.power + str(word).lower() +' ' * self.power\n",
    "        res =[]\n",
    "        for sh in range(self.power+2):\n",
    "            grams = [w[i:i+self.power+1] for i in range(sh,len(w)-self.power+2-sh)]\n",
    "            res.append(np.prod([self.get_pair_proba(c1, c2) for c1, c2 in zip(grams, grams[1+self.power:])]))\n",
    "        return max(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paswords = x_train['Password'].to_list() + x_test['Password'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markov = MarkovChain()\n",
    "# markov.fit(all_paswords)\n",
    "# pickle.dump(markov, open('markov.pkl', 'wb'))\n",
    "# markov_2 = MarkovChain(2)\n",
    "# markov_2.fit(all_paswords)\n",
    "# pickle.dump(markov_2, open('markov_2.pkl', 'wb'))\n",
    "# markov_3 = MarkovChain(3)\n",
    "# markov_3.fit(all_paswords)\n",
    "# pickle.dump(markov_3, open('markov_3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('markov.pkl'):\n",
    "    markov = pickle.load(open('markov.pkl', 'rb'))\n",
    "else:\n",
    "    markov = MarkovChain()\n",
    "    markov.fit(all_paswords)\n",
    "    pickle.dump(markov, open('markov.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('markov_2.pkl'):\n",
    "    markov_2 = pickle.load(open('markov_2.pkl', 'rb'))\n",
    "else:\n",
    "    markov_2 = MarkovChain(2)\n",
    "    markov_2.fit(all_paswords)\n",
    "    pickle.dump(markov_2, open('markov_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('markov_3.pkl'):\n",
    "    markov_3 = pickle.load(open('markov_3.pkl', 'rb'))\n",
    "else:\n",
    "    markov_3 = MarkovChain(3)\n",
    "    markov_3.fit(all_paswords)\n",
    "    pickle.dump(markov_3, open('markov_3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('markov_4.pkl'):\n",
    "    markov_4 = pickle.load(open('markov_4.pkl', 'rb'))\n",
    "else:\n",
    "    markov_4 = MarkovChain(4)\n",
    "    markov_4.fit(all_paswords)\n",
    "    pickle.dump(markov_3, open('markov_4.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features(in_data):\n",
    "    data = in_data.copy()\n",
    "    data['Password'] = data['Password'].apply(lambda x: str(x))  #convert to string\n",
    "    cols = data.columns\n",
    "    if 'len' not in cols:\n",
    "        data['len'] = data['Password'].apply(lambda x: len(x)) #get len\n",
    "    \n",
    "    if 'len_low' not in cols:\n",
    "        data['len_low'] = data['Password'].apply(lambda x: len(re.findall(r\"[a-z]\", x)))\n",
    "        data['is_low'] = (data['len_low'] > 0).astype(int)\n",
    "        data['p_low'] = data['len_low']/data['len'] \n",
    "    \n",
    "    if 'len_caps' not in cols:\n",
    "        data['len_caps'] = data['Password'].apply(lambda x: len(re.findall(r\"[A-Z]\", x)))\n",
    "        data['is_caps'] = (data['len_caps'] > 0).astype(int)\n",
    "        data['p_caps'] = data['len_caps']/data['len']\n",
    "        \n",
    "    if 'len_numb' not in cols:\n",
    "        data['len_numb'] = data['Password'].apply(lambda x: len(re.findall(r\"[0-9]\", x)))\n",
    "        data['is_numb'] = (data['len_numb'] > 0).astype(int)\n",
    "        data['p_numb'] = data['len_numb']/data['len'] \n",
    "    \n",
    "    if 'len_spec' not in cols:\n",
    "        data['len_spec'] = data['Password'].apply(lambda x: len(re.findall(r\"[^a-zA-Z0-9]\", x)))\n",
    "        data['is_spec'] = (data['len_spec'] > 0).astype(int)\n",
    "        data['p_spec'] = data['len_spec']/data['len'] \n",
    "    \n",
    "    if 'len_uniq' not in cols:\n",
    "        data['len_uniq'] = data['Password'].apply(lambda x: len(set(x)))\n",
    "        data['p_uniq'] = data['len_uniq']/data['len'] \n",
    "    \n",
    "    if 'score' not in cols:\n",
    "        data['score'] = data['is_low'] + data['is_caps'] + data['is_numb'] + data['is_spec']\n",
    "        \n",
    "    if 'w_distance' not in cols:   \n",
    "        data['w_distance'] = data['Password'].apply(wordTotalDistance)\n",
    "        \n",
    "    if 'markov_proba' not in cols: \n",
    "        data['markov_proba'] = data['Password'].apply(markov.proba)\n",
    "        \n",
    "    if 'markov_proba_2' not in cols: \n",
    "        data['markov_proba_2'] = data['Password'].apply(markov_2.proba)\n",
    "        \n",
    "    if 'markov_proba_3' not in cols: \n",
    "        data['markov_proba_3'] = data['Password'].apply(markov_3.proba)\n",
    "        \n",
    "    if 'markov_proba_4' not in cols: \n",
    "        data['markov_proba_4'] = data['Password'].apply(markov_4.proba)\n",
    "    \n",
    "    #data.drop(columns=['Password'], inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = gen_features(x)\n",
    "# pickle.dump(x, open('x.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('x.pkl'):\n",
    "    x = pickle.load(open('x.pkl', 'rb'))\n",
    "else:\n",
    "    x = gen_features(x_train)\n",
    "    pickle.dump(x, open('x.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('y.pkl'):\n",
    "    y = pickle.load(open('y.pkl', 'rb'))\n",
    "else:\n",
    "    train = pd.read_csv(train_file, dtype={'Password': str, 'Times': np.int32})\n",
    "    y = np.log(train['Times']+1)\n",
    "    pickle.dump(y, open('y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x.drop(columns=['Password']), y, test_size=split_part, random_state = split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = LinearRegression(n_jobs=4)\n",
    "reg1.fit(X_train, y_train)\n",
    "y_train_pred1 = reg1.predict(X_train)\n",
    "y_val_pred1 = reg1.predict(X_val)\n",
    "print('rmlse_train: ', np.sqrt(mean_squared_error(y_train, y_train_pred1)))\n",
    "print('rmlse_val: ', np.sqrt(mean_squared_error(y_val, y_val_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lr_pred'] = y_train_pred1\n",
    "X_val['lr_pred'] = y_val_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = RandomForestRegressor(random_state=model_seed, verbose=2, n_estimators=200, n_jobs=4, max_depth =20)\n",
    "reg = LGBMRegressor(num_leaves=63, max_depth=-1, learning_rate=0.1, n_estimators = 500, n_jobs=4, random_state=model_seed)\n",
    "reg.fit(X_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_orig = reg.predict(X_train)\n",
    "y_val_pred_orig = reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmlse_train = np.sqrt(mean_squared_error(y_train, y_train_pred_orig))\n",
    "rmlse_val = np.sqrt(mean_squared_error(y_val, y_val_pred_orig))\n",
    "print('rmlse_train: ', rmlse_train)\n",
    "print('rmlse_val: ', rmlse_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmlse_train:  0.33885744320234273\n",
    "rmlse_val:  0.3455145745624136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare answers and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = LinearRegression(n_jobs=4)\n",
    "reg1.fit(x.drop(columns=['Password']), y)\n",
    "x['lr_pred'] = reg1.predict(x.drop(columns=['Password']))\n",
    "print('LR rmlse_train: ', np.sqrt(mean_squared_error(y, x['lr_pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LGBMRegressor(num_leaves=63, max_depth=-1, learning_rate=0.1, n_estimators = 500, n_jobs=4, random_state=model_seed)\n",
    "reg.fit(x.drop(columns=['Password']), y)\n",
    "y_pred_x = reg.predict(x.drop(columns=['Password']))\n",
    "print('LGB rmlse_train: ', np.sqrt(mean_squared_error(y, y_pred_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(x_test_fin, open('x_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_fin = pickle.load(open('x_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_fin = gen_features(x_test_fin.drop(columns=['markov_proba', 'markov_proba_2', 'markov_proba_3']))\n",
    "x_test_fin['lr_pred'] = reg1.predict(x_test_fin.drop(columns=['Password']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test_fin.drop(columns=['Password']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(y_pred) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred < 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': x_test.index,\n",
    "                       'Times': y_pred})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit result\n",
    "message = 'LR => LGBM default; error mean correction; updated loss approach; markov 1st, 2nd, 3rd chain'\n",
    "result = api.competition_submit('submission.csv', message, competition)\n",
    "\n",
    "# get last submissioon data\n",
    "import time\n",
    "last_result = api.competition_submissions(competition)[0]\n",
    "while getattr(last_result, 'status') != 'complete':\n",
    "    time.sleep(5)\n",
    "    last_result = api.competition_submissions(competition)[0]\n",
    "fields = ['date', 'description', 'status', 'publicScore', 'ref', 'submittedBy']\n",
    "\n",
    "#dict to store detials\n",
    "res_details = {}\n",
    "for f in fields:\n",
    "    res_details[f] = getattr(last_result, f)\n",
    "print(res_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
