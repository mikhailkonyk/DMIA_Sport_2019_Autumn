{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:42:52.787898Z",
     "start_time": "2019-10-12T06:42:44.201601Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:42:55.329435Z",
     "start_time": "2019-10-12T06:42:52.789900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_full = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('Xtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:42:57.576138Z",
     "start_time": "2019-10-12T06:42:55.332433Z"
    }
   },
   "outputs": [],
   "source": [
    "# оставляем семпл из трейна (так как комп не тянет больше) - сохраняем баланс 1/не 1\n",
    "\n",
    "df_train_full = pd.concat([df_train_full[df_train_full['Times'] == 1].sample(frac = 0.7, random_state = 7).copy(), \n",
    "                      df_train_full[(df_train_full['Times'] > 1)].sample(frac = 0.7, random_state = 7).copy()])\n",
    "\n",
    "df_train_full = df_train_full.sample(frac = 1, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:42:58.981891Z",
     "start_time": "2019-10-12T06:42:57.577697Z"
    }
   },
   "outputs": [],
   "source": [
    "# считаем количество символов\n",
    "\n",
    "for df_ in [df_train_full, df_test]:\n",
    "    df_['len'] = df_['Password'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:43:12.869859Z",
     "start_time": "2019-10-12T06:42:58.982891Z"
    }
   },
   "outputs": [],
   "source": [
    "# добавляем индикаторы только нижний/верхний регистр и т.д.\n",
    "\n",
    "for df_ in [df_train_full, df_test]:\n",
    "    df_['lower'] = (df_['Password'].str.lower() == df_['Password']).astype(int)\n",
    "    df_['upper'] = (df_['Password'].str.upper() == df_['Password']).astype(int)\n",
    "    df_['alpha'] = (df_['Password'].str.isalpha() == True).astype(int)\n",
    "    df_['isnumeric'] = (df_['Password'].str.isnumeric() == True).astype(int)\n",
    "    df_['isalnum'] = (df_['Password'].str.isalnum() == True).astype(int)\n",
    "    df_['title'] = (df_['Password'].str.istitle() == True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:47:46.987701Z",
     "start_time": "2019-10-12T06:43:12.871872Z"
    }
   },
   "outputs": [],
   "source": [
    "# cчитаем количество различных символов в пароле\n",
    "\n",
    "def string_vectorizer(strng, characters=(string.ascii_lowercase + string.digits + string.punctuation)):\n",
    "    vector = [strng.lower().count(char) for char in characters] \n",
    "    return vector\n",
    "\n",
    "for df_ in [df_train_full, df_test]:\n",
    "    for ch in list(string.ascii_lowercase + string.digits + string.punctuation):\n",
    "        df_[ch] = np.NaN\n",
    "    df_[list(string.ascii_lowercase + string.digits + string.punctuation)] = [string_vectorizer(str(df_['Password'].iloc[i])) for i in range(len(df_))]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:48:16.458126Z",
     "start_time": "2019-10-12T06:47:46.992694Z"
    }
   },
   "outputs": [],
   "source": [
    "# считаем число уникальных символов и всех символов разных видов и некоторые логичные отношения\n",
    "\n",
    "for df_ in [df_train_full, df_test]:\n",
    "    df_['len_set'] = (df_[list(string.ascii_lowercase + string.digits + string.punctuation)] > 0).astype(int).sum(axis = 1)\n",
    "    df_['len_set_ch'] = (df_[list(string.ascii_lowercase)] > 0).astype(int).sum(axis = 1)\n",
    "    df_['len_set_dig'] = (df_[list(string.digits)] > 0).astype(int).sum(axis = 1)\n",
    "    df_['len_set_punc'] = (df_[list(string.punctuation)] > 0).astype(int).sum(axis = 1)\n",
    "    \n",
    "    df_['len_ch'] = df_[list(string.ascii_lowercase)].sum(axis = 1)\n",
    "    df_['len_dig'] = df_[list(string.digits)].sum(axis = 1)\n",
    "    df_['len_punc'] = df_[list(string.punctuation)].sum(axis = 1)\n",
    "    \n",
    "    df_['ratio_unique'] = df_['len_set']/df_['len']\n",
    "    \n",
    "    df_['ratio_unique_ch'] = df_['len_set_ch']/df_['len_set']\n",
    "    df_['ratio_unique_dig'] = df_['len_set_dig']/df_['len_set']\n",
    "    df_['ratio_unique_punc'] = df_['len_set_punc']/df_['len_set']\n",
    "    \n",
    "    df_['ratio_ch'] = df_['len_ch']/df_['len']\n",
    "    df_['ratio_dig'] = df_['len_dig']/df_['len']\n",
    "    df_['ratio_punc'] = df_['len_punc']/df_['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:51:35.407505Z",
     "start_time": "2019-10-12T06:50:56.050175Z"
    }
   },
   "outputs": [],
   "source": [
    "# смотрим наличие некоторых специальных комбинаций\n",
    "\n",
    "for df_ in [df_train_full, df_test]:\n",
    "    for password in ['123', '111', '234', '987', '432']:\n",
    "        df_[password] = ((df_['Password'].str.contains(password)) == True).astype(int)\n",
    "for df_ in [df_train_full, df_test]:\n",
    "    for password in ['qwe', 'qaz', 'pass', 'abc', 'asd']:\n",
    "        df_[password] = ((df_['Password'].str.lower().str.contains(password)) == True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:57:19.574758Z",
     "start_time": "2019-10-12T06:57:19.567759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['len', 'lower', 'upper', 'alpha', 'isnumeric', 'isalnum', 'title', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'len_set', 'len_set_ch', 'len_set_dig', 'len_set_punc', 'len_ch', 'len_dig', 'len_punc', 'ratio_unique', 'ratio_unique_ch', 'ratio_unique_dig', 'ratio_unique_punc', 'ratio_ch', 'ratio_dig', 'ratio_punc', '123', '111', '234', '987', '432', 'qwe', 'qaz', 'pass', 'abc', 'asd'] 99\n"
     ]
    }
   ],
   "source": [
    "# создаем список фичей для модели\n",
    "\n",
    "list_feat = list(df_train_full.columns[2:])\n",
    "print(list_feat, len(list_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T21:14:51.864739Z",
     "start_time": "2019-10-02T21:13:05.784Z"
    }
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:58:57.080250Z",
     "start_time": "2019-10-12T06:58:57.019285Z"
    }
   },
   "outputs": [],
   "source": [
    "# делаем преобразование над таргетом\n",
    "\n",
    "df_train_full['target'] = np.log(df_train_full['Times'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:59:02.487132Z",
     "start_time": "2019-10-12T06:59:02.268270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  2324837 \n",
      "Valid:  581210 \n",
      "Test:  1037875\n"
     ]
    }
   ],
   "source": [
    "# разбиваем на трейн и валид\n",
    "\n",
    "df_train, df_valid = df_train_full[:int(0.8*len(df_train_full))], df_train_full[int(0.8*len(df_train_full)):]\n",
    "\n",
    "print('Train: ', len(df_train), '\\nValid: ', len(df_valid),'\\nTest: ',  len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:59:11.280058Z",
     "start_time": "2019-10-12T06:59:11.275061Z"
    }
   },
   "outputs": [],
   "source": [
    "# пишем нужную метрику\n",
    "\n",
    "def rmsle(y_test, predictions):\n",
    "    return np.sqrt(mean_squared_log_error(y_test, predictions))\n",
    "\n",
    "def rmse(y_test, predictions):\n",
    "    return np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T07:57:16.619033Z",
     "start_time": "2019-10-12T06:59:20.035006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE 0.377 params {'num_leaves': 32, 'learning_rate': 0.438, 'min_child_samples': 12, 'feature_fraction': 0.65, 'bagging_fraction': 0.8500000000000001, 'lambda_l2': 1.167, 'lambda_l1': 0.97, 'n_estimators': 44}\n",
      "RMSLE 0.375 params {'num_leaves': 106, 'learning_rate': 0.766, 'min_child_samples': 19, 'feature_fraction': 0.75, 'bagging_fraction': 0.65, 'lambda_l2': 0.907, 'lambda_l1': 0.752, 'n_estimators': 182}\n",
      "RMSLE 0.377 params {'num_leaves': 74, 'learning_rate': 0.023, 'min_child_samples': 12, 'feature_fraction': 0.35000000000000003, 'bagging_fraction': 0.6000000000000001, 'lambda_l2': 1.046, 'lambda_l1': 1.318, 'n_estimators': 444}\n",
      "RMSLE 0.373 params {'num_leaves': 50, 'learning_rate': 0.456, 'min_child_samples': 17, 'feature_fraction': 0.75, 'bagging_fraction': 1.0, 'lambda_l2': 1.143, 'lambda_l1': 0.9430000000000001, 'n_estimators': 273}\n",
      "RMSLE 0.374 params {'num_leaves': 89, 'learning_rate': 0.47900000000000004, 'min_child_samples': 17, 'feature_fraction': 0.5, 'bagging_fraction': 0.8500000000000001, 'lambda_l2': 1.414, 'lambda_l1': 0.541, 'n_estimators': 137}\n",
      "RMSLE 0.375 params {'num_leaves': 107, 'learning_rate': 0.166, 'min_child_samples': 17, 'feature_fraction': 0.6000000000000001, 'bagging_fraction': 0.55, 'lambda_l2': 1.393, 'lambda_l1': 0.659, 'n_estimators': 65}\n",
      "RMSLE 0.377 params {'num_leaves': 63, 'learning_rate': 0.636, 'min_child_samples': 9, 'feature_fraction': 0.9, 'bagging_fraction': 0.55, 'lambda_l2': 1.1360000000000001, 'lambda_l1': 0.11, 'n_estimators': 395}\n",
      "RMSLE 0.381 params {'num_leaves': 77, 'learning_rate': 0.534, 'min_child_samples': 16, 'feature_fraction': 0.25, 'bagging_fraction': 0.8500000000000001, 'lambda_l2': 0.10300000000000001, 'lambda_l1': 0.905, 'n_estimators': 10}\n",
      "RMSLE 0.379 params {'num_leaves': 89, 'learning_rate': 0.53, 'min_child_samples': 11, 'feature_fraction': 0.8500000000000001, 'bagging_fraction': 0.2, 'lambda_l2': 0.895, 'lambda_l1': 1.11, 'n_estimators': 374}\n",
      "RMSLE 0.377 params {'num_leaves': 21, 'learning_rate': 0.462, 'min_child_samples': 12, 'feature_fraction': 0.65, 'bagging_fraction': 0.5, 'lambda_l2': 0.614, 'lambda_l1': 0.974, 'n_estimators': 77}\n",
      "RMSLE 0.372 params {'num_leaves': 125, 'learning_rate': 0.4, 'min_child_samples': 15, 'feature_fraction': 0.8500000000000001, 'bagging_fraction': 1.0, 'lambda_l2': 1.2670000000000001, 'lambda_l1': 1.3940000000000001, 'n_estimators': 176}\n",
      "RMSLE 0.372 params {'num_leaves': 123, 'learning_rate': 0.362, 'min_child_samples': 14, 'feature_fraction': 0.65, 'bagging_fraction': 0.9, 'lambda_l2': 0.627, 'lambda_l1': 1.053, 'n_estimators': 443}\n",
      "RMSLE 0.374 params {'num_leaves': 85, 'learning_rate': 0.361, 'min_child_samples': 11, 'feature_fraction': 0.30000000000000004, 'bagging_fraction': 0.45, 'lambda_l2': 1.093, 'lambda_l1': 1.216, 'n_estimators': 459}\n",
      "RMSLE 0.382 params {'num_leaves': 67, 'learning_rate': 0.011, 'min_child_samples': 7, 'feature_fraction': 0.25, 'bagging_fraction': 0.35000000000000003, 'lambda_l2': 0.06, 'lambda_l1': 0.47500000000000003, 'n_estimators': 377}\n",
      "RMSLE 0.375 params {'num_leaves': 86, 'learning_rate': 0.022, 'min_child_samples': 11, 'feature_fraction': 0.9500000000000001, 'bagging_fraction': 0.7000000000000001, 'lambda_l2': 0.189, 'lambda_l1': 0.754, 'n_estimators': 430}\n",
      "RMSLE 0.376 params {'num_leaves': 100, 'learning_rate': 0.227, 'min_child_samples': 7, 'feature_fraction': 0.5, 'bagging_fraction': 0.9500000000000001, 'lambda_l2': 0.531, 'lambda_l1': 1.387, 'n_estimators': 32}\n",
      "RMSLE 0.377 params {'num_leaves': 24, 'learning_rate': 0.331, 'min_child_samples': 17, 'feature_fraction': 0.4, 'bagging_fraction': 0.25, 'lambda_l2': 0.971, 'lambda_l1': 1.06, 'n_estimators': 170}\n",
      "RMSLE 0.374 params {'num_leaves': 76, 'learning_rate': 0.369, 'min_child_samples': 15, 'feature_fraction': 0.30000000000000004, 'bagging_fraction': 0.4, 'lambda_l2': 0.135, 'lambda_l1': 1.456, 'n_estimators': 366}\n",
      "RMSLE 0.377 params {'num_leaves': 110, 'learning_rate': 0.548, 'min_child_samples': 13, 'feature_fraction': 0.15000000000000002, 'bagging_fraction': 0.2, 'lambda_l2': 1.2690000000000001, 'lambda_l1': 0.745, 'n_estimators': 287}\n",
      "RMSLE 0.375 params {'num_leaves': 87, 'learning_rate': 0.523, 'min_child_samples': 11, 'feature_fraction': 0.7000000000000001, 'bagging_fraction': 0.55, 'lambda_l2': 0.335, 'lambda_l1': 0.587, 'n_estimators': 354}\n",
      "RMSLE 0.372 params {'num_leaves': 124, 'learning_rate': 0.26, 'min_child_samples': 2, 'feature_fraction': 0.8500000000000001, 'bagging_fraction': 0.75, 'lambda_l2': 0.728, 'lambda_l1': 1.238, 'n_estimators': 499}\n",
      "RMSLE 0.372 params {'num_leaves': 127, 'learning_rate': 0.632, 'min_child_samples': 20, 'feature_fraction': 0.9500000000000001, 'bagging_fraction': 1.0, 'lambda_l2': 0.435, 'lambda_l1': 1.491, 'n_estimators': 219}\n",
      "RMSLE 0.373 params {'num_leaves': 119, 'learning_rate': 0.134, 'min_child_samples': 14, 'feature_fraction': 0.8, 'bagging_fraction': 0.9500000000000001, 'lambda_l2': 0.8, 'lambda_l1': 0.342, 'n_estimators': 311}\n",
      "RMSLE 0.374 params {'num_leaves': 114, 'learning_rate': 0.29, 'min_child_samples': 19, 'feature_fraction': 0.55, 'bagging_fraction': 0.8, 'lambda_l2': 1.497, 'lambda_l1': 1.169, 'n_estimators': 117}\n",
      "RMSLE 0.373 params {'num_leaves': 99, 'learning_rate': 0.633, 'min_child_samples': 8, 'feature_fraction': 1.0, 'bagging_fraction': 0.9, 'lambda_l2': 0.684, 'lambda_l1': 1.319, 'n_estimators': 217}\n",
      "RMSLE 0.373 params {'num_leaves': 126, 'learning_rate': 0.181, 'min_child_samples': 5, 'feature_fraction': 0.45, 'bagging_fraction': 0.75, 'lambda_l2': 0.307, 'lambda_l1': 1.453, 'n_estimators': 318}\n",
      "RMSLE 0.376 params {'num_leaves': 57, 'learning_rate': 0.082, 'min_child_samples': 14, 'feature_fraction': 0.6000000000000001, 'bagging_fraction': 0.1, 'lambda_l2': 0.544, 'lambda_l1': 1.053, 'n_estimators': 236}\n",
      "RMSLE 0.375 params {'num_leaves': 10, 'learning_rate': 0.38, 'min_child_samples': 15, 'feature_fraction': 0.75, 'bagging_fraction': 0.9500000000000001, 'lambda_l2': 1.2510000000000001, 'lambda_l1': 1.302, 'n_estimators': 486}\n",
      "RMSLE 0.375 params {'num_leaves': 41, 'learning_rate': 0.789, 'min_child_samples': 9, 'feature_fraction': 0.65, 'bagging_fraction': 0.9, 'lambda_l2': 0.807, 'lambda_l1': 0.855, 'n_estimators': 112}\n",
      "RMSLE 0.373 params {'num_leaves': 119, 'learning_rate': 0.41000000000000003, 'min_child_samples': 19, 'feature_fraction': 0.8500000000000001, 'bagging_fraction': 0.8, 'lambda_l2': 0.40800000000000003, 'lambda_l1': 1.133, 'n_estimators': 176}\n",
      "100%|██████████| 30/30 [57:56<00:00, 104.54s/it, best loss: 0.3719704780271286]\n"
     ]
    }
   ],
   "source": [
    "# подбираем гиперпараметры\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'learning_rate' : params['learning_rate'],\n",
    "        'min_child_samples' : int(params['min_child_samples']),\n",
    "        'feature_fraction' : params['feature_fraction'],\n",
    "        'bagging_fraction' : params['bagging_fraction'],\n",
    "        'lambda_l2' : params['lambda_l2'],\n",
    "        'lambda_l1' : params['lambda_l1'],\n",
    "        'n_estimators' :  int(params['n_estimators'])\n",
    "    }    \n",
    "    gbm = lgb.LGBMRegressor(\n",
    "        min_data_per_group = 2,\n",
    "        reg_sqrt = True,\n",
    "        num_threads = 8,\n",
    "        objective = 'mse',\n",
    "        bagging_freq = 5,\n",
    "        boost_from_average = True,\n",
    "        seed = 42,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    score = rmse(df_train['target'], cross_val_predict(gbm, df_train[list_feat].values, \n",
    "                                                                        (df_train['target']), \n",
    "                                                                        cv = KFold(n_splits = 3, \n",
    "                                                                        random_state = 18, \n",
    "                                                                        shuffle=True)))\n",
    "\n",
    "    print(\"RMSLE {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 10, 500, 1),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.8, 0.001),\n",
    "    'min_child_samples' : hp.quniform('min_child_samples', 1, 20, 1),\n",
    "    'num_leaves' : hp.quniform('num_leaves', 8, 128, 1),\n",
    "    'feature_fraction' : hp.quniform('feature_fraction', 0.05, 1.0, 0.05),\n",
    "    'bagging_fraction' : hp.quniform('bagging_fraction', 0.1, 1.0, 0.05),\n",
    "    'lambda_l2' : hp.quniform('lambda_l2', 0.001, 1.5, 0.001),\n",
    "    'lambda_l1' : hp.quniform('lambda_l1', 0.001, 1.5, 0.001)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T07:57:28.843036Z",
     "start_time": "2019-10-12T07:57:28.828045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperopt estimated optimum {'bagging_fraction': 0.9, 'feature_fraction': 0.65, 'lambda_l1': 1.053, 'lambda_l2': 0.627, 'learning_rate': 0.362, 'min_child_samples': 14.0, 'n_estimators': 443.0, 'num_leaves': 123.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "\n",
    "best = {\n",
    "        'num_leaves': int(best['num_leaves']),\n",
    "        'learning_rate' : best['learning_rate'],\n",
    "        'min_child_samples' : int(best['min_child_samples']),\n",
    "        'feature_fraction' : best['feature_fraction'],\n",
    "        'bagging_fraction' : best['bagging_fraction'],\n",
    "        'lambda_l2' : best['lambda_l2'],\n",
    "        'lambda_l1' : best['lambda_l1'],\n",
    "        'n_estimators' :  int(best['n_estimators'])\n",
    "    }    \n",
    "\n",
    "gbm2 = lgb.LGBMRegressor(\n",
    "        min_data_per_group = 2,\n",
    "        reg_sqrt = True,\n",
    "        num_threads = 8,\n",
    "        objective = 'mse',\n",
    "        bagging_freq = 5,\n",
    "        boost_from_average = True,\n",
    "        seed = 42,\n",
    "        **best\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T07:59:16.090991Z",
     "start_time": "2019-10-12T07:57:37.812862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3687\n"
     ]
    }
   ],
   "source": [
    "# проверяем точность на валидации\n",
    "\n",
    "fitted = gbm2.fit(df_train[list_feat].values, df_train['target'])\n",
    "df_valid['predict'] = np.clip(np.exp(fitted.predict(df_valid[list_feat].values)) - 1, 1, np.inf)\n",
    "rmsle_valid = np.round(rmsle(df_valid['Times'], df_valid['predict']), 4)                           \n",
    "print(rmsle_valid.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T08:01:42.675741Z",
     "start_time": "2019-10-12T07:59:24.999850Z"
    }
   },
   "outputs": [],
   "source": [
    "# делаем прогноз и пишем в файл\n",
    "\n",
    "gbm2.fit(df_train_full[list_feat].values, (df_train_full['target']))\n",
    "df_test['Times'] = np.clip(np.exp(gbm2.predict(df_test[list_feat])) - 1, 1, np.inf)\n",
    "df_test[['Id', 'Times']].to_csv('sumbit_sport_6_'+str(date.today())+'_'+str(rmsle_valid)+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Models Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:48:16.497105Z",
     "start_time": "2019-10-12T06:42:44.212Z"
    }
   },
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv('sumbit_sport_6_2019-10-06_0.3748951815393266.csv')\n",
    "#df2 = pd.read_csv('sumbit_sport_5_2019-10-05_0.37305721354473675.csv')\n",
    "#df3 = pd.read_csv('sumbit_sport_4_2019-10-05_0.3733657824992114.csv')\n",
    "#df_concat = pd.concat((df1, df2, df3))\n",
    "#by_row_index = df_concat.groupby(df_concat.index)\n",
    "#df_means = by_row_index.mean()\n",
    "#df_means[['Id', 'Times']].to_csv('submit_sport_mean_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
